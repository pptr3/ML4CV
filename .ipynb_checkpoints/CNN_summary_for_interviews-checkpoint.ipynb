{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725fbc7a",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "**Softmax**\n",
    "- $softmax(scores_j) = \\frac{exp(s_j)}{sum(exp(s_{all}))}$\n",
    "\n",
    "**Cross-entropy loss**\n",
    "- $-log(softmax(f(x;\\theta)))$\n",
    "\n",
    "**ADAM**\n",
    "- $g^{(t + 1)} = \\beta_1 g^{(t)} + (1 - \\beta_1)\\nabla L (\\theta ^{(t)})$\n",
    "- $s^{(t + 1)} = \\beta_2 s^{(t)} + (1 - \\beta_2)\\nabla L (\\theta ^{(t)}) * \\nabla L (\\theta ^{(t)})$\n",
    "- $g^{debiased} = \\frac{g^{(t+1)}}{1-\\beta_1^{t+1}}$, $s^{debiased} = \\frac{s^{(t+1)}}{1-\\beta_2^{t+1}}$\n",
    "- $\\theta^{(t+1)} = \\theta^{(t)} - \\frac{lr}{\\sqrt{s^{debiased}}+ \\epsilon} * g^{debiased}$\n",
    "\n",
    "**Relationship between spatial dim**\n",
    "- $H_{out} = H_{in} - H_k + 1$\n",
    "- $W_{out} = W_{in} - W_k + 1$\n",
    "\n",
    "**Padding**\n",
    "- $H_{out} = H_{in} - H_k + 1 + 2P$\n",
    "- $W_{out} = W_{in} - W_k + 1 + 2P$\n",
    "\n",
    "**Stride**\n",
    "- $H_{out} = inf[\\frac{(H_{in} - H_k + 2P)}{S}] + 1$\n",
    "- $W_{out} = inf[\\frac{(W_{in} - W_k + 2P)}{S}] + 1$\n",
    "\n",
    "**Boosting**\n",
    "- Boosting is a way to train and build an ensemble of _M_ week learners (WL) to obtain a strong learner (SL). How good a WL should be to make this work? They just need to be better than a random guess (> 50% of accuracy).\n",
    "\n",
    "**Random forests (is a bagging algorithm)**\n",
    "- are an ensemble of simple classifiers (that usually have low bias and high variance), in this case decision/regressor trees. Each tree is trained **on a random view of the dataset** and then the output is the average of their predictions.\n",
    "- the trees should be very different from each other because different trees will make different errors and averaging their predicions at the end we will obtain a lower error. How to make trees different from each other? We should train them on different datasets, but usually we do not have many datasets, so **we simulate them!**.\n",
    "- **how we simulate different datasets starting from just one? Bagging!**\n",
    "    - we start from the dataset and randomly and **with replacements** we create a new version of the dataset and use this dataset to create a tree, the proceed doing the same for the second tree and so on.\n",
    "    - at each node, the trees define the split on a random subset of features, this reduces the correlation between trees.\n",
    "- **when to use Random forests?** When we have classifiers with low bias with the aim to reduce the overall variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d3bdc",
   "metadata": {},
   "source": [
    "# Probability\n",
    "\n",
    "- **Conditional Probability** P(A|B) è la probabilità che un evento A si verifichi, in base al verificarsi di un evento precedente B.\n",
    "\n",
    "- **Independent events** sono eventi il cui esito non influenza la probabilità dell'esito di un altro evento.\n",
    "    - **P(A|B) = P(A)**\n",
    "    - **P(B|A) = P(B)**\n",
    "    - **P(A intersecato B) = P(A)P(B)**\n",
    "\n",
    "\n",
    "- **Bayes’ Theorem**: una formula matematica per determinare la probabilità condizionata.\n",
    "    - <img src=\"bayes.png\" width=\"50%\" height=\"50%\">\n",
    "\n",
    "- **Teorema probabilità totale**\n",
    "    - <img src=\"totale.png\" width=\"50%\" height=\"50%\">\n",
    "    \n",
    "- **Valore atteso/medio**\n",
    "    - <img src=\"valoreatteso.png\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b3478",
   "metadata": {},
   "source": [
    "# Stats\n",
    "- **varianza** misura la distribuzione di un insieme di dati rispetto alla media.\n",
    "    - <img src=\"variance.png\" width=\"30%\" height=\"30%\">\n",
    "- **std**\n",
    "    - square root of variance\n",
    "- **covarianza** misura la varianza tra due (o più) variabili. Se è positivo, tendono a muoversi nella stessa direzione, se è negativo, tendono a muoversi in direzioni opposte, e se sono pari a zero, non hanno alcuna relazione tra loro.\n",
    "    - <img src=\"covariance.png\" width=\"30%\" height=\"30%\">\n",
    "- **correlazione** misura la forza di una relazione tra due variabili e va da -1 a 1; è la versione normalizzata della covarianza.\n",
    "    - <img src=\"correlation.png\" width=\"30%\" height=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f221793",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a22a8aa8",
   "metadata": {},
   "source": [
    "# COME\n",
    "## Se io ho un dataset sbilanciato con due classi, quali sono i modi per bilanciarlo, che risultati mi aspetterei da un modello trained su un dataset sbilanciato e che risultati mi aspetterei da un modello dopo il bilanciamento, che metriche guardo to asses model quality:\n",
    "\n",
    "COME BILANCIARE UN DATASET\n",
    "\n",
    "**Sottostima delle classi maggioritarie**: Durante il training, si può utilizzare una tecnica di sottostima delle classi maggioritarie, in modo che la rete neurale riceva più esempi della classe minoritaria. Oppure, al contrario, una sovrastima della classe minoritaria generando ad esempio nuovi dati sintetici.\n",
    "\n",
    "**Generazione di dati sintetici**: si può utilizzare una tecnica di generazione di dati sintetici, come l'algoritmo SMOTE (Synthetic Minority Over-Sampling Technique), per generare nuovi esempi della classe minoritaria interpolando tra gli esempi esistenti della classe minoritaria.\n",
    "    \n",
    "METRICHE DATASET SBILANCIATO\n",
    "\n",
    "**Metriche di classificazione**: precision, recall e l'F1-score.\n",
    "\n",
    "**Matrice di confusione**: la matrice di confusione può essere utilizzata per visualizzare la performance del modello su ogni classe del dataset. **NEL CASO DI UN DATASET SBILANCIATO**, una confusion matrix può mostrare un alto numero di TN rispetto a TP o FP, questo significa che la maggior parte delle predizioni del modello sono state corrette per la classe maggioritaria, ma può avere difficoltà nel riconoscere la classe minoritaria. **POST BILANCIAMENTO** mi aspetto valori più equilibrati tra le diverse classi.\n",
    "\n",
    "**Metrica AUC-ROC**: l'AUC-ROC (Area Under the Receiver Operating Characteristic) è una metrica di classificazione binaria utilizzata per valutare la capacità di un modello di distinguere tra due classi prescindendo dalla relativa frequenza delle classi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e90ff5f",
   "metadata": {},
   "source": [
    "## Se io avessi un modello che deve gestire 100 richieste contemporaneamente, come si può fare?\n",
    "- Uno dei modi più comuni è utilizzare un'architettura distribuita, in cui il modello è eseguito su più macchine o nodi contemporaneamente per gestire più richieste.\n",
    "- Esistono anche servizi tipo Tryton per testare quante richieste gestisce modello\n",
    "- Riduzione latency (tempo impiegato per processare un dato) o throughput (quante richieste può gestire in a given amount of time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d48b9",
   "metadata": {},
   "source": [
    "## Fine tuning, quali sono i modi per farlo e come funziona\n",
    "- Transfer learning quando:\n",
    "    - small dataset\n",
    "    - salvare computation\n",
    "- **Fine-tuning completo**: consiste nell'addestrare tutti gli strati del modello pre-addestrato su un nuovo dataset. Questo tipo di fine-tuning è utile quando il nuovo dataset è simile al dataset originale su cui è stato addestrato il modello pre-addestrato.\n",
    "- **Fine-tuning parziale**: consiste nell'addestrare solo alcuni strati del modello pre-addestrato su un nuovo dataset. Questo tipo di fine-tuning è utile quando il nuovo dataset ha caratteristiche differenti rispetto al dataset originale, in questo modo si evita che la rete apprenda caratteristiche non pertinenti.\n",
    "\n",
    "## Cosa memorizza in RAM una CNN\n",
    "- per la CNN avrai i pesi dei filtri, dei batch norm, e dell'MLP. Per ogni training step avrai i risultati intermedi, e i gradienti.\n",
    "\n",
    "## Perchè l'input di una rete neurale è di solito fisso ma in alcune reti / problemi non è fisso e perchè non lo è?\n",
    "- In una CNN ad esempio è fisso perchè abbiamo bisogno di prendere in input una immagine di una fixed size. Ma se ad esempio abbiamo un modello di NLP, in input abbiamo una frase di lunghezza variabile\n",
    "\n",
    "## Problema 49 persone con radar\n",
    "- 4 persone randmiche su 49 hanno un pezzo di metallo. Tutte e 49 passano davanti ad un metal detector. Quante persone in media passano davanti al metal detector prima che il primo col metallo venga detectato? Le 4 persone dividono in 5 gruppi l'insieme, quindi alla fine il problema diventa \"quante persone ci sono nel primo gruppo\"; dato che ci sono 49 persone, ne togliamo 4 perchè hanno il metallo, quindi 45, essendo che le 4 persone formano 5 gruppi (una per gruppo), 45/5 —> 9 è la risposta\n",
    "\n",
    "## Problema dado\n",
    "- un dado normale, qual è il valore medio lanciando un dado a 6 facce (vedere teoria del valor medio)? 1/6 per ogni value, quindi 6+5+4+3+2+1 == 21, 21/6 == 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f0ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4410c88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
