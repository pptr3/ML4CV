{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax**\n",
    "- $softmax(scores_j) = \\frac{exp(s_j)}{sum(exp(s_{all}))}$\n",
    "\n",
    "**Cross-entropy loss**\n",
    "- $-log(softmax(f(x;\\theta)))$\n",
    "\n",
    "**Momentum**\n",
    "- $v^{(t + 1)}  = \\beta v^{(t)} - lr \\nabla L(\\theta^{(t)})$\n",
    "- $\\theta^{(t+1)} = \\theta^{(t)} + v^{(t + 1)}$\n",
    "- $v^{(t + 1)}$ contains a running average of the previous update steps\n",
    "\n",
    "**Nesterov momentum**\n",
    "- very similar to *momentum*, but the gradient is computed after having \"partially\" updated $\\theta^{(t)}$ with $\\beta v^{(t)}$:\n",
    "- $v^{(t + 1)}  = \\beta v^{(t)} - lr \\nabla L(\\theta^{(t)} + \\beta v^{(t)})$\n",
    "- $\\theta^{(t+1)} = \\theta^{(t)} + v^{(t + 1)}$\n",
    "- Nesterov momentum shows a faster convergence\n",
    "\n",
    "**AdaGrad**\n",
    "- $s^{(t + 1)} = s^{(t)} + \\nabla L (\\theta ^{(t)}) * \\nabla L (\\theta ^{(t)})$, this $s$ is the history of the squared gradients\n",
    "- $\\theta ^{(t + 1)} =  \\theta ^{(t)} - \\frac{lr}{\\sqrt{s^{(t+1)}}+ \\epsilon} * \\nabla L (\\theta ^{(t)})$\n",
    "\n",
    "**RMSProp**\n",
    "- $s^{(t + 1)} = \\beta s^{(t)} + (1 - \\beta)\\nabla L (\\theta ^{(t)}) * \\nabla L (\\theta ^{(t)})$, this $s$ is the history of the squared gradients\n",
    "- $\\theta ^{(t + 1)} =  \\theta ^{(t)} - \\frac{lr}{\\sqrt{s^{(t+1)}}+ \\epsilon} * \\nabla L (\\theta ^{(t)})$\n",
    "\n",
    "**ADAM**\n",
    "- $g^{(t + 1)} = \\beta_1 g^{(t)} + (1 - \\beta_1)\\nabla L (\\theta ^{(t)})$\n",
    "- $s^{(t + 1)} = \\beta_2 s^{(t)} + (1 - \\beta_2)\\nabla L (\\theta ^{(t)}) * \\nabla L (\\theta ^{(t)})$\n",
    "- $g^{debiased} = \\frac{g^{(t+1)}}{1-\\beta_1^{t+1}}$, $s^{debiased} = \\frac{s^{(t+1)}}{1-\\beta_2^{t+1}}$\n",
    "- $\\theta^{(t+1)} = \\theta^{(t)} - \\frac{lr}{\\sqrt{s^{debiased}}+ \\epsilon} * g^{debiased}$\n",
    "\n",
    "**Relationship between spatial dim**\n",
    "- $H_{out} = H_{in} - H_k + 1$\n",
    "- $W_{out} = W_{in} - W_k + 1$\n",
    "\n",
    "**Padding**\n",
    "- $H_{out} = H_{in} - H_k + 1 + 2P$\n",
    "- $W_{out} = W_{in} - W_k + 1 + 2P$\n",
    "\n",
    "**Stride**\n",
    "- $H_{out} = inf[\\frac{(H_{in} - H_k + 2P)}{S}] + 1$\n",
    "- $W_{out} = inf[\\frac{(W_{in} - W_k + 2P)}{S}] + 1$\n",
    "\n",
    "**Formula of learnable parameters**: are all weights of all the kernels. So in general we apply a conv with a kernel $16 \\times 8 \\times 5 \\times 5$ with 16 being \"how many kernels apply\", then the overall formula for the learnable parameters is:\n",
    "- $16 \\times (8 \\times 5 \\times 5 + 1)$ (+1 for the bias)\n",
    "\n",
    "**Formula of flops**\n",
    "- output feature map $\\times$ 3D kernel size $\\times 2$\n",
    "- the latter $\\times 2$ is because we perform $n$ summation and $n$ multiplications\n",
    "\n",
    "**Polyak average**\n",
    "- $$\\theta^{(test)} = (1-\\rho)\\theta^{(i+1)} + \\rho\\theta^{(test)}$$\n",
    "\n",
    "**Integral image**\n",
    "- $$II(i, j) = II(i, j-1) + II(i-1, j) - II(i-1, j-1) + I(i, j)$$\n",
    "\n",
    "**Focal loss**\n",
    "- $$BFL(p_t) = -(1-p_t)^y ln p_t$$\n",
    "- <img src=\"pt.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "**Contrastive loss**\n",
    "- <img src=\"con.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "**Hinge loss**\n",
    "- <img src=\"hinge.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "**Triplet loss + margin**\n",
    "- <img src=\"triplet2.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "**EfficientNet**\n",
    "- <img src=\"eff.png\" width=\"70%\" height=\"70%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
